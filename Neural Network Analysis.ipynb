{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae34e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#read data into data frame, data\n",
    "data = pd.read_excel(&quot;Stroke Data.xlsx&quot;)\n",
    "\n",
    "21\n",
    "\n",
    "# Fill missing values with mean column values in the data set\n",
    "# In this case, Age had some holes\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "#drop the columns that we don&#39;t need!\n",
    "#data = data.drop([&#39;index&#39;], axis=1)\n",
    "labelEncoder = LabelEncoder()\n",
    "labelEncoder.fit(data[&#39;gender&#39;])\n",
    "data[&#39;gender&#39;] = labelEncoder.transform(data[&#39;gender&#39;])\n",
    "labelEncoder = LabelEncoder()\n",
    "labelEncoder.fit(data[&#39;ever_married&#39;])\n",
    "data[&#39;ever_married&#39;] = labelEncoder.transform(data[&#39;ever_married&#39;])\n",
    "labelEncoder = LabelEncoder()\n",
    "labelEncoder.fit(data[&#39;work_type&#39;])\n",
    "data[&#39;work_type&#39;] = labelEncoder.transform(data[&#39;work_type&#39;])\n",
    "labelEncoder = LabelEncoder()\n",
    "labelEncoder.fit(data[&#39;Residence_type&#39;])\n",
    "data[&#39;Residence_type&#39;] = labelEncoder.transform(data[&#39;Residence_type&#39;])\n",
    "labelEncoder = LabelEncoder()\n",
    "labelEncoder.fit(data[&#39;smoking_status&#39;])\n",
    "data[&#39;smoking_status&#39;] = labelEncoder.transform(data[&#39;smoking_status&#39;])\n",
    "#list all of the predictors that will be used\n",
    "predictors =\n",
    "[&#39;age&#39;,&#39;heart_disease&#39;,&#39;gender&#39;,&#39;Residence_type&#39;,&#39;avg_glucose_level&#39;,&#39;bmi&#39;,&#39;ever_married&#39;,&#39;work_typ\n",
    "e&#39;,&#39;smoking_status&#39;,&#39;hypertension&#39;]\n",
    "#set up target, predictors, and split the training/testing partitions\n",
    "X = data[predictors]\n",
    "y = data[&#39;stroke&#39;]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "#Normalize your data Here!!\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "# Now apply the transformations to the data:\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "22\n",
    "\n",
    "X_test = scaler.transform(X_test)\n",
    "#####################################################################\n",
    "print(&quot;Model 1 - (3) with solver=&#39;adam&#39;,activation=&#39;relu&#39;&quot;)\n",
    "#create the neural network with your choice of hidden layer size\n",
    "#If your sample size is NOT in the thousands, use solver=&#39;lbfgs&#39;\n",
    "network = MLPClassifier(hidden_layer_sizes=(3), max_iter=400,\n",
    "solver=&#39;adam&#39;,activation=&#39;relu&#39;)\n",
    "network.fit(X_train, y_train)\n",
    "#test the model against our new model and calculate the accuracy\n",
    "pred = network.predict(X_test)\n",
    "print(&quot;Accuracy:&quot;, round(accuracy_score(y_test, pred),3))\n",
    "#create confusion matrix and print it\n",
    "confusionMatrix = pd.DataFrame(\n",
    "confusion_matrix(y_test, pred),\n",
    "columns=[&#39;Predicted No Stroke&#39;,&#39;Predicted Stroke&#39;],\n",
    "index=[&#39;True No Stroke&#39;,&#39;True Stroke&#39;]\n",
    ")\n",
    "print(confusionMatrix)\n",
    "print()\n",
    "#####################################################################\n",
    "print(&quot;Model 2 - (4,4) with solver=&#39;lbfgs&#39;,activation=&#39;logistic&#39;&quot;)\n",
    "#create the neural network with your choice of hidden layer size\n",
    "#If your sample size is NOT in the thousands, use solver=&#39;lbfgs&#39;\n",
    "network2 =\n",
    "MLPClassifier(hidden_layer_sizes=(4,4),max_iter=400,solver=&#39;lbfgs&#39;,activation=&#39;logistic&#39;)\n",
    "network2.fit(X_train, y_train)\n",
    "#test the model against our new model and calculate the accuracy\n",
    "pred = network2.predict(X_test)\n",
    "print(&quot;Accuracy:&quot;, round(accuracy_score(y_test, pred),3))\n",
    "#create confusion matrix and print it\n",
    "confusionMatrix = pd.DataFrame(\n",
    "confusion_matrix(y_test, pred),\n",
    "columns=[&#39;Predicted No Stroke&#39;,&#39;Predicted Stroke&#39;],\n",
    "index=[&#39;True No Stroke&#39;,&#39;True Stroke&#39;]\n",
    ")\n",
    "\n",
    "23\n",
    "\n",
    "print(confusionMatrix)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
